<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="copyright" content="© 2025 Pranshu Kumar Chaudhary. All Rights Reserved.">
    <meta name="author" content="Pranshu Kumar Chaudhary">
    <title>AI & Machine Learning Technology Radar - TRL Visualization</title>
    <link rel="stylesheet" href="experimental-design.css">
    <style>
        /* Clean Radar Visualization Styles */
        body {
            background: var(--color-white);
            color: var(--color-black);
            overflow-x: hidden;
            font-family: var(--font-primary);
        }

        .radar-container {
            position: relative;
            width: 100vw;
            height: 100vh;
            display: flex;
            flex-direction: column;
            background: var(--color-white);
        }

        .radar-header {
            position: absolute;
            top: 20px;
            left: 20px;
            z-index: 100;
        }

        .radar-title {
            font-size: 24px;
            font-weight: 700;
            color: var(--color-electric-blue);
            margin: 0;
        }

        .radar-subtitle {
            font-size: 12px;
            color: var(--color-gray-600);
            margin: 5px 0 10px 0;
            text-transform: uppercase;
            letter-spacing: 2px;
        }

        .trl-info-btn {
            background: var(--color-electric-blue) !important;
            color: var(--color-white) !important;
            border-color: var(--color-electric-blue) !important;
        }

        .trl-info-btn:hover {
            background: var(--color-electric-blue-dark) !important;
            border-color: var(--color-electric-blue-dark) !important;
            color: var(--color-white) !important;
        }

        .controls-panel {
            position: absolute;
            top: 20px;
            right: 20px;
            z-index: 100;
            display: flex;
            flex-direction: column;
            gap: 10px;
        }

        .control-group {
            background: var(--color-white);
            border: 1px solid var(--color-gray-200);
            border-radius: 5px;
            padding: 10px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }

        .control-label {
            font-size: 10px;
            color: var(--color-gray-600);
            text-transform: uppercase;
            margin-bottom: 5px;
            letter-spacing: 1px;
            font-weight: 600;
        }

        .filter-buttons {
            display: flex;
            gap: 5px;
            flex-wrap: wrap;
        }

        .filter-btn {
            padding: 5px 10px;
            background: var(--color-gray-100);
            border: 1px solid var(--color-gray-300);
            color: var(--color-gray-700);
            font-size: 10px;
            cursor: pointer;
            transition: all 0.3s ease;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 500;
        }

        .filter-btn:hover {
            background: var(--color-electric-blue-bg);
            border-color: var(--color-electric-blue);
            color: var(--color-electric-blue);
        }

        .filter-btn.active {
            background: var(--color-electric-blue);
            border-color: var(--color-electric-blue);
            color: var(--color-white);
        }

        .radar-canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }

        .zoom-controls {
            position: absolute;
            left: 20px;
            top: 50%;
            transform: translateY(-50%);
            display: flex;
            flex-direction: column;
            gap: 10px;
            z-index: 100;
        }

        .zoom-btn {
            width: 40px;
            height: 40px;
            background: var(--color-white);
            border: 1px solid var(--color-gray-300);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 18px;
            font-weight: 600;
            color: var(--color-gray-700);
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }

        .zoom-btn:hover {
            background: var(--color-electric-blue);
            color: var(--color-white);
            border-color: var(--color-electric-blue);
        }

        .info-panel {
            position: absolute;
            bottom: 20px;
            left: 20px;
            right: 20px;
            background: var(--color-white);
            border: 1px solid var(--color-gray-200);
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
            opacity: 0;
            transform: translateY(100%);
            transition: all 0.4s ease;
            max-height: 400px;
            overflow-y: auto;
        }

        .info-panel.active {
            opacity: 1;
            transform: translateY(0);
        }

        .info-title {
            font-size: 18px;
            color: var(--color-electric-blue);
            margin: 0 0 10px 0;
            font-weight: 700;
        }

        .info-meta {
            display: flex;
            gap: 15px;
            margin-bottom: 15px;
            flex-wrap: wrap;
        }

        .meta-badge {
            padding: 3px 8px;
            border-radius: 3px;
            font-size: 10px;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
        }

        .meta-research { background: var(--color-electric-blue); color: var(--color-white); }
        .meta-industry { background: var(--color-gray-800); color: var(--color-white); }
        .meta-emerging { background: var(--color-gray-600); color: var(--color-white); }
        .meta-experimental { background: var(--color-electric-blue-dark); color: var(--color-white); }

        .info-description {
            color: var(--color-gray-700);
            line-height: 1.6;
            margin-bottom: 15px;
            font-size: 14px;
        }

        .references-section {
            margin-top: 20px;
            padding-top: 15px;
            border-top: 1px solid var(--color-gray-200);
        }

        .references-title {
            font-size: 14px;
            font-weight: 600;
            color: var(--color-black);
            margin-bottom: 10px;
        }

        .reference-item {
            margin-bottom: 8px;
            font-size: 12px;
            color: var(--color-gray-600);
        }

        .reference-link {
            color: var(--color-electric-blue);
            text-decoration: none;
        }

        .reference-link:hover {
            text-decoration: underline;
        }

        .progress-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 10px;
        }

        .progress-item {
            background: var(--color-gray-50);
            border: 1px solid var(--color-gray-200);
            border-radius: 5px;
            padding: 10px;
        }

        .progress-label {
            font-size: 10px;
            color: var(--color-gray-600);
            text-transform: uppercase;
            margin-bottom: 5px;
            font-weight: 600;
        }

        .progress-bar {
            width: 100%;
            height: 8px;
            background: var(--color-gray-200);
            border-radius: 4px;
            overflow: hidden;
            margin-bottom: 5px;
        }

        .progress-fill {
            height: 100%;
            background: var(--color-electric-blue);
            transition: width 0.8s ease;
        }

        .progress-value {
            font-size: 12px;
            color: var(--color-electric-blue);
            font-weight: 600;
        }

        .close-btn {
            position: absolute;
            top: 10px;
            right: 15px;
            background: none;
            border: none;
            color: var(--color-gray-500);
            font-size: 20px;
            cursor: pointer;
            transition: color 0.3s ease;
        }

        .close-btn:hover {
            color: var(--color-electric-blue);
        }

        .legend {
            position: absolute;
            bottom: 20px;
            right: 20px;
            background: var(--color-white);
            border: 1px solid var(--color-gray-200);
            border-radius: 5px;
            padding: 15px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }

        .trl-info-panel {
            position: absolute;
            top: 20px;
            left: 50%;
            transform: translateX(-50%);
            background: var(--color-white);
            border: 2px solid var(--color-electric-blue);
            border-radius: 10px;
            padding: 20px;
            max-width: 600px;
            width: 90%;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.15);
            opacity: 0;
            visibility: hidden;
            transition: all 0.4s ease;
            z-index: 200;
        }

        .trl-info-panel.active {
            opacity: 1;
            visibility: visible;
        }

        .trl-info-title {
            font-size: 18px;
            font-weight: 700;
            color: var(--color-electric-blue);
            margin-bottom: 15px;
        }

        .trl-info-content {
            color: var(--color-gray-700);
            line-height: 1.6;
            font-size: 14px;
            margin-bottom: 20px;
        }

        .trl-levels-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 10px;
            margin-bottom: 15px;
        }

        .trl-level-item {
            padding: 8px;
            background: var(--color-gray-50);
            border-radius: 4px;
            font-size: 11px;
            text-align: center;
        }

        .trl-level-number {
            font-weight: 600;
            color: var(--color-electric-blue);
        }

        .close-info-btn {
            position: absolute;
            top: 10px;
            right: 15px;
            background: none;
            border: none;
            font-size: 20px;
            color: var(--color-gray-500);
            cursor: pointer;
            transition: color 0.3s ease;
        }

        .close-info-btn:hover {
            color: var(--color-electric-blue);
        }

        .legend-title {
            font-size: 12px;
            color: var(--color-electric-blue);
            margin-bottom: 10px;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
        }

        .legend-item {
            display: flex;
            align-items: center;
            gap: 8px;
            margin-bottom: 5px;
            font-size: 10px;
            color: var(--color-gray-700);
        }

        .legend-color {
            width: 12px;
            height: 12px;
            border-radius: 2px;
        }

        .loading {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: #00f5ff;
            font-size: 14px;
            text-transform: uppercase;
            letter-spacing: 2px;
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 0.4; }
            50% { opacity: 1; }
        }

        @media (max-width: 1024px) {
            .radar-container {
                height: auto;
                min-height: 100vh;
                padding-bottom: 20px;
            }

            .radar-header {
                position: static;
                margin: 20px;
            }

            .radar-canvas {
                position: relative;
                width: 100%;
                height: 70vh;
            }

            .controls-panel {
                position: static;
                margin: 10px 20px 0 20px;
            }

            .legend {
                position: static;
                margin: 10px 20px;
            }

            .zoom-controls {
                position: static;
                transform: none;
                flex-direction: row;
                justify-content: center;
                margin: 10px 0;
            }
        }

        @media (max-width: 768px) {
            .radar-container {
                height: auto;
                min-height: 100vh;
                padding-bottom: 16px;
            }

            .radar-title {
                font-size: 18px;
            }

            .radar-header {
                position: static;
                margin: 16px;
            }

            .radar-canvas {
                position: relative;
                width: 100%;
                height: 60vh;
            }

            .controls-panel {
                position: static;
                top: auto;
                right: auto;
                margin: 10px 16px 0 16px;
            }

            .legend {
                position: static;
                bottom: auto;
                right: auto;
                margin: 10px 16px;
            }

            .zoom-controls {
                position: static;
                transform: none;
                flex-direction: row;
                justify-content: center;
                margin: 10px 0;
            }
        }
    </style>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-R4MBJ1TPQ5"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-R4MBJ1TPQ5');
    </script>
</head>
<body>
    <div class="radar-container">
        <div class="radar-header">
            <h1 class="radar-title">AI & MACHINE LEARNING TECHNOLOGY RADAR</h1>
            <p class="radar-subtitle">Technology Readiness Level Visualization</p>
        </div>

        <div class="controls-panel">
            <div class="control-group">
                <div class="control-label">Filter by Origin</div>
                <div class="filter-buttons">
                    <button class="filter-btn active" data-filter="all">ALL</button>
                    <button class="filter-btn" data-filter="research">RESEARCH</button>
                    <button class="filter-btn" data-filter="industry">INDUSTRY</button>
                    <button class="filter-btn" data-filter="emerging">EMERGING</button>
                    <button class="filter-btn" data-filter="experimental">EXPERIMENTAL</button>
                </div>
            </div>

            <div class="control-group">
                <div class="control-label">Time Period</div>
                <div class="filter-buttons">
                    <button class="filter-btn active" data-time="2025">2025</button>
                    <button class="filter-btn" data-time="2020">2020</button>
                    <button class="filter-btn" data-time="2015">2015</button>
                </div>
            </div>

            <div class="control-group">
                <div class="control-label">Learn More</div>
                <div class="filter-buttons">
                    <button class="filter-btn trl-info-btn" onclick="toggleTRLInfo()">WHAT IS TRL?</button>
                </div>
            </div>

            <div class="control-group">
                <div class="control-label">Navigate</div>
                <div class="filter-buttons">
                    <button class="filter-btn" onclick="window.location.href='index.html'">HOME</button>
                    <button class="filter-btn" onclick="window.location.href='ai-landing.html'">LANDING</button>
                </div>
                <div class="filter-buttons" style="margin-top: 5px;">
                    <select class="trl-dropdown" onchange="if(this.value) window.location.href=this.value;" style="width: 100%; padding: 8px; border: 1px solid var(--color-gray-300); border-radius: 4px; background: var(--color-white); color: var(--color-gray-700); font-size: 10px; text-transform: uppercase; letter-spacing: 1px; font-weight: 500; cursor: pointer;">
                        <option value="">EXPLORE OTHER TRL RADARS ▼</option>
                        <option value="ai-trl.html" disabled selected>AI & Machine Learning</option>
                        <option value="blockchain-trl.html">Blockchain</option>
                        <option value="biorobotics-trl.html">Bio-Robotics</option>
                        <option value="edge-trl.html">Edge Computing</option>
                        <option value="interfaces-trl.html">Future Interfaces</option>
                        <option value="iot-trl.html">Internet of Things</option>
                        <option value="metaverse-trl.html">Metaverse</option>
                        <option value="quantum-trl.html">Quantum Computing</option>
                        <option value="robotics-trl.html">Robotics</option>
                        <option value="textiles-trl.html">Smart Textiles</option>
                    </select>
                </div>
            </div>
        </div>

        <div class="zoom-controls">
            <button class="zoom-btn" id="zoomIn" title="Zoom In">+</button>
            <button class="zoom-btn" id="zoomOut" title="Zoom Out">−</button>
            <button class="zoom-btn" id="resetZoom" title="Reset Zoom">⌂</button>
        </div>

        <svg class="radar-canvas" id="radarSvg"></svg>

        <div class="trl-info-panel" id="trlInfoPanel">
            <button class="close-info-btn" onclick="toggleTRLInfo()">×</button>
            <div class="trl-info-title">Technology Readiness Levels (TRL)</div>
            <div class="trl-info-content">
                Technology Readiness Levels for AI & Machine Learning assess maturity from basic research to widespread deployment. TRL evaluation considers model accuracy, computational efficiency, data requirements, deployment scale, regulatory compliance, and real-world performance across diverse applications including enterprise, consumer, and research contexts.
            </div>
            <div class="trl-levels-grid">
                <div class="trl-level-item">
                    <div class="trl-level-number">TRL 1-2</div>
                    <div>Basic Research</div>
                </div>
                <div class="trl-level-item">
                    <div class="trl-level-number">TRL 3</div>
                    <div>Proof of Concept</div>
                </div>
                <div class="trl-level-item">
                    <div class="trl-level-number">TRL 4</div>
                    <div>Lab Validation</div>
                </div>
                <div class="trl-level-item">
                    <div class="trl-level-number">TRL 5</div>
                    <div>Benchmark Testing</div>
                </div>
                <div class="trl-level-item">
                    <div class="trl-level-number">TRL 6</div>
                    <div>Pilot Deployment</div>
                </div>
                <div class="trl-level-item">
                    <div class="trl-level-number">TRL 7</div>
                    <div>Beta Release</div>
                </div>
                <div class="trl-level-item">
                    <div class="trl-level-number">TRL 8</div>
                    <div>Production System</div>
                </div>
                <div class="trl-level-item">
                    <div class="trl-level-number">TRL 9</div>
                    <div>Proven Operational</div>
                </div>
                <div class="trl-level-item" style="grid-column: span 1; background: var(--color-electric-blue-bg);">
                    <div class="trl-level-number">Click & Explore</div>
                    <div>Interactive Technologies</div>
                </div>
            </div>
        </div>

        <div class="legend">
            <div class="legend-title">TRL Levels</div>
            <div class="legend-item">
                <div class="legend-color" style="background: #a3a3a3;"></div>
                <span>TRL 1-3: Research</span>
            </div>
            <div class="legend-item">
                <div class="legend-color" style="background: #525252;"></div>
                <span>TRL 4-6: Development</span>
            </div>
            <div class="legend-item">
                <div class="legend-color" style="background: #4040ff;"></div>
                <span>TRL 7-9: Production</span>
            </div>
        </div>

        <div class="info-panel" id="infoPanel">
            <button class="close-btn" onclick="closeInfoPanel()">×</button>
            <div id="infoPanelContent">
                <!-- Dynamic content will be loaded here -->
            </div>
        </div>

        <div class="loading" id="loadingIndicator">Initializing Radar...</div>
    </div>

    <script>
        const technologyData = {
            2015: [
                { id: 'image-classification', name: 'Image Classification (ImageNet)', category: 'industry', trl: 7, angle: 0, progress: { research: 75, funding: 80, timeline: 70, consensus: 78 } },
                { id: 'speech-recognition', name: 'Speech Recognition', category: 'industry', trl: 7, angle: 15, progress: { research: 70, funding: 75, timeline: 65, consensus: 72 } },
                { id: 'recommendation', name: 'Recommendation Systems', category: 'industry', trl: 8, angle: 30, progress: { research: 85, funding: 90, timeline: 80, consensus: 88 } },
                { id: 'machine-translation', name: 'Machine Translation', category: 'industry', trl: 6, angle: 45, progress: { research: 60, funding: 65, timeline: 55, consensus: 62 } },
                { id: 'object-detection', name: 'Object Detection', category: 'emerging', trl: 6, angle: 60, progress: { research: 65, funding: 70, timeline: 60, consensus: 68 } },
                { id: 'sentiment-analysis', name: 'Sentiment Analysis', category: 'emerging', trl: 5, angle: 75, progress: { research: 50, funding: 55, timeline: 45, consensus: 52 } },
                { id: 'neural-networks', name: 'Deep Neural Networks', category: 'research', trl: 5, angle: 90, progress: { research: 55, funding: 60, timeline: 50, consensus: 58 } },
                { id: 'nlp-basic', name: 'Natural Language Processing', category: 'research', trl: 4, angle: 105, progress: { research: 45, funding: 50, timeline: 40, consensus: 48 } },
                { id: 'chatbots', name: 'Rule-Based Chatbots', category: 'emerging', trl: 6, angle: 120, progress: { research: 60, funding: 65, timeline: 55, consensus: 62 } },
                { id: 'face-recognition', name: 'Face Recognition', category: 'emerging', trl: 6, angle: 135, progress: { research: 65, funding: 70, timeline: 60, consensus: 68 } },
                { id: 'anomaly-detection', name: 'Anomaly Detection', category: 'research', trl: 4, angle: 150, progress: { research: 40, funding: 45, timeline: 35, consensus: 42 } },
                { id: 'reinforcement-learning', name: 'Reinforcement Learning', category: 'research', trl: 3, angle: 165, progress: { research: 30, funding: 35, timeline: 25, consensus: 32 } },
                { id: 'gan-basic', name: 'Generative Adversarial Networks', category: 'research', trl: 2, angle: 180, progress: { research: 20, funding: 25, timeline: 15, consensus: 22 } },
                { id: 'transfer-learning', name: 'Transfer Learning', category: 'research', trl: 3, angle: 195, progress: { research: 35, funding: 40, timeline: 30, consensus: 37 } },
                { id: 'autonomous-driving', name: 'Autonomous Driving Research', category: 'research', trl: 3, angle: 210, progress: { research: 35, funding: 50, timeline: 30, consensus: 38 } },
                { id: 'ml-frameworks', name: 'ML Frameworks (TensorFlow)', category: 'emerging', trl: 5, angle: 225, progress: { research: 50, funding: 60, timeline: 45, consensus: 52 } },
                { id: 'computer-vision', name: 'Computer Vision Libraries', category: 'industry', trl: 7, angle: 240, progress: { research: 70, funding: 75, timeline: 65, consensus: 72 } },
                { id: 'neural-architecture', name: 'Neural Architecture Research', category: 'research', trl: 2, angle: 255, progress: { research: 25, funding: 30, timeline: 20, consensus: 27 } },
                { id: 'ai-ethics', name: 'AI Ethics Research', category: 'research', trl: 1, angle: 270, progress: { research: 15, funding: 20, timeline: 10, consensus: 17 } },
                { id: 'explainability', name: 'Model Explainability', category: 'research', trl: 2, angle: 285, progress: { research: 20, funding: 25, timeline: 15, consensus: 22 } },
                { id: 'edge-ai-basic', name: 'Edge AI Concepts', category: 'research', trl: 3, angle: 300, progress: { research: 30, funding: 35, timeline: 25, consensus: 32 } },
                { id: 'few-shot', name: 'Few-Shot Learning', category: 'research', trl: 2, angle: 315, progress: { research: 25, funding: 30, timeline: 20, consensus: 27 } },
                { id: 'ai-chips-early', name: 'Early AI Accelerators', category: 'research', trl: 4, angle: 330, progress: { research: 40, funding: 50, timeline: 35, consensus: 42 } },
                { id: 'federated-basic', name: 'Federated Learning Concepts', category: 'research', trl: 2, angle: 345, progress: { research: 20, funding: 25, timeline: 15, consensus: 22 } }
            ],
            2020: [
                { id: 'image-classification', name: 'Computer Vision (YOLO, ResNet)', category: 'industry', trl: 9, angle: 0, progress: { research: 95, funding: 98, timeline: 95, consensus: 97 } },
                { id: 'speech-recognition', name: 'Speech Recognition (Whisper)', category: 'industry', trl: 8, angle: 15, progress: { research: 85, funding: 90, timeline: 82, consensus: 88 } },
                { id: 'recommendation', name: 'Recommendation Engines', category: 'industry', trl: 9, angle: 30, progress: { research: 95, funding: 100, timeline: 95, consensus: 98 } },
                { id: 'machine-translation', name: 'Neural Machine Translation', category: 'industry', trl: 8, angle: 45, progress: { research: 85, funding: 90, timeline: 82, consensus: 88 } },
                { id: 'transformers', name: 'Transformer Models (BERT, GPT-2)', category: 'emerging', trl: 7, angle: 60, progress: { research: 75, funding: 85, timeline: 70, consensus: 78 } },
                { id: 'gpt3', name: 'Large Language Models (GPT-3)', category: 'emerging', trl: 6, angle: 75, progress: { research: 70, funding: 80, timeline: 65, consensus: 73 } },
                { id: 'object-detection', name: 'Object Detection (Faster R-CNN)', category: 'industry', trl: 8, angle: 90, progress: { research: 85, funding: 90, timeline: 82, consensus: 88 } },
                { id: 'gan-images', name: 'GAN Image Generation', category: 'emerging', trl: 6, angle: 105, progress: { research: 65, funding: 70, timeline: 60, consensus: 68 } },
                { id: 'chatbots-ai', name: 'AI-Powered Chatbots', category: 'industry', trl: 7, angle: 120, progress: { research: 75, funding: 80, timeline: 70, consensus: 77 } },
                { id: 'face-recognition', name: 'Face Recognition Systems', category: 'industry', trl: 8, angle: 135, progress: { research: 82, funding: 88, timeline: 78, consensus: 83 } },
                { id: 'autonomous-l2', name: 'Autonomous Driving L2-3', category: 'emerging', trl: 6, angle: 150, progress: { research: 65, funding: 75, timeline: 60, consensus: 68 } },
                { id: 'reinforcement-learning', name: 'Reinforcement Learning (AlphaGo)', category: 'emerging', trl: 6, angle: 165, progress: { research: 70, funding: 75, timeline: 65, consensus: 72 } },
                { id: 'transfer-learning', name: 'Transfer Learning', category: 'industry', trl: 7, angle: 180, progress: { research: 75, funding: 80, timeline: 70, consensus: 77 } },
                { id: 'automl', name: 'Aut oML Platforms', category: 'emerging', trl: 6, angle: 195, progress: { research: 60, funding: 65, timeline: 55, consensus: 62 } },
                { id: 'edge-ai', name: 'Edge AI Inference', category: 'emerging', trl: 6, angle: 210, progress: { research: 65, funding: 70, timeline: 60, consensus: 68 } },
                { id: 'ai-chips', name: 'AI Chips (TPU v3, GPUs)', category: 'industry', trl: 7, angle: 225, progress: { research: 78, funding: 85, timeline: 75, consensus: 80 } },
                { id: 'federated-learning', name: 'Federated Learning', category: 'research', trl: 5, angle: 240, progress: { research: 50, funding: 55, timeline: 45, consensus: 52 } },
                { id: 'ai-ethics', name: 'AI Ethics & Fairness', category: 'research', trl: 4, angle: 255, progress: { research: 45, funding: 50, timeline: 40, consensus: 48 } },
                { id: 'explainability', name: 'Explainable AI (XAI)', category: 'research', trl: 5, angle: 270, progress: { research: 50, funding: 55, timeline: 45, consensus: 52 } },
                { id: 'few-shot', name: 'Few-Shot & Zero-Shot Learning', category: 'research', trl: 4, angle: 285, progress: { research: 45, funding: 50, timeline: 40, consensus: 48 } },
                { id: 'alphafold', name: 'AI for Protein Folding', category: 'research', trl: 5, angle: 300, progress: { research: 55, funding: 65, timeline: 50, consensus: 58 } },
                { id: 'neuromorphic', name: 'Neuromorphic Computing', category: 'research', trl: 3, angle: 315, progress: { research: 35, funding: 40, timeline: 30, consensus: 37 } },
                { id: 'quantum-ml', name: 'Quantum Machine Learning', category: 'research', trl: 3, angle: 330, progress: { research: 30, funding: 35, timeline: 25, consensus: 32 } },
                { id: 'bci-ml', name: 'Brain-Computer ML Interfaces', category: 'research', trl: 3, angle: 345, progress: { research: 35, funding: 40, timeline: 30, consensus: 37 } }
            ],
            2025: [
                { id: 'llm', name: 'Large Language Models (GPT-4o, Claude, Gemini)', category: 'industry', trl: 8, angle: 0, progress: { research: 95, funding: 100, timeline: 92, consensus: 96 } },
                { id: 'computer-vision', name: 'Computer Vision (SAM, YOLO v10)', category: 'industry', trl: 9, angle: 15, progress: { research: 98, funding: 100, timeline: 98, consensus: 99 } },
                { id: 'speech-recognition', name: 'Speech Recognition (Whisper v3)', category: 'industry', trl: 9, angle: 30, progress: { research: 95, funding: 98, timeline: 95, consensus: 97 } },
                { id: 'recommendation', name: 'AI Recommendation Systems', category: 'industry', trl: 9, angle: 45, progress: { research: 98, funding: 100, timeline: 98, consensus: 99 } },
                { id: 'machine-translation', name: 'Neural Machine Translation', category: 'industry', trl: 9, angle: 60, progress: { research: 95, funding: 98, timeline: 95, consensus: 97 } },
                { id: 'code-assistants', name: 'AI Code Assistants (Copilot, Cursor)', category: 'industry', trl: 8, angle: 75, progress: { research: 88, funding: 95, timeline: 85, consensus: 90 } },
                { id: 'gen-ai-images', name: 'Generative AI Images (Midjourney, DALL-E)', category: 'industry', trl: 8, angle: 90, progress: { research: 85, funding: 92, timeline: 82, consensus: 88 } },
                { id: 'autonomous-l3', name: 'Autonomous Vehicles L2-3 (Tesla, Waymo)', category: 'industry', trl: 7, angle: 105, progress: { research: 80, funding: 95, timeline: 75, consensus: 83 } },
                { id: 'multimodal-ai', name: 'Multimodal AI (GPT-4V, Gemini 2.0)', category: 'industry', trl: 7, angle: 120, progress: { research: 82, funding: 90, timeline: 78, consensus: 85 } },
                { id: 'ai-agents', name: 'AI Agents & Autonomous Systems', category: 'emerging', trl: 6, angle: 135, progress: { research: 70, funding: 78, timeline: 65, consensus: 73 } },
                { id: 'rag', name: 'Retrieval Augmented Generation', category: 'industry', trl: 7, angle: 150, progress: { research: 78, funding: 82, timeline: 75, consensus: 80 } },
                { id: 'video-generation', name: 'AI Video Generation (Sora, Runway)', category: 'emerging', trl: 6, angle: 165, progress: { research: 72, funding: 85, timeline: 65, consensus: 75 } },
                { id: 'federated-learning', name: 'Federated Learning Systems', category: 'emerging', trl: 6, angle: 180, progress: { research: 65, funding: 70, timeline: 60, consensus: 68 } },
                { id: 'edge-ai', name: 'Edge AI Inference (Jetson, Coral)', category: 'industry', trl: 7, angle: 195, progress: { research: 80, funding: 85, timeline: 75, consensus: 82 } },
                { id: 'ai-chips', name: 'AI Chips (TPU v5, Trainium, Cerebras)', category: 'industry', trl: 8, angle: 210, progress: { research: 88, funding: 95, timeline: 85, consensus: 90 } },
                { id: 'automl', name: 'Neural Architecture Search (AutoML)', category: 'emerging', trl: 6, angle: 225, progress: { research: 68, funding: 72, timeline: 62, consensus: 70 } },
                { id: 'quantum-ml', name: 'Quantum Machine Learning', category: 'research', trl: 4, angle: 240, progress: { research: 48, funding: 55, timeline: 42, consensus: 50 } },
                { id: 'neuromorphic', name: 'Neuromorphic Computing (Loihi 2)', category: 'research', trl: 4, angle: 255, progress: { research: 45, funding: 50, timeline: 40, consensus: 48 } },
                { id: 'ai-safety', name: 'AI Safety & Alignment Research', category: 'research', trl: 5, angle: 270, progress: { research: 55, funding: 65, timeline: 50, consensus: 58 } },
                { id: 'few-shot', name: 'Few-Shot & In-Context Learning', category: 'research', trl: 5, angle: 285, progress: { research: 58, funding: 62, timeline: 52, consensus: 60 } },
                { id: 'causal-ai', name: 'Causal AI & Reasoning', category: 'research', trl: 4, angle: 300, progress: { research: 50, funding: 55, timeline: 45, consensus: 52 } },
                { id: 'explainability', name: 'Explainable AI (XAI)', category: 'research', trl: 5, angle: 315, progress: { research: 60, funding: 65, timeline: 55, consensus: 62 } },
                { id: 'bci-ml', name: 'Brain-Computer ML Interfaces', category: 'research', trl: 4, angle: 330, progress: { research: 48, funding: 55, timeline: 42, consensus: 50 } },
                { id: 'ai-science', name: 'AI for Scientific Discovery (AlphaFold 3)', category: 'emerging', trl: 6, angle: 345, progress: { research: 75, funding: 85, timeline: 70, consensus: 78 } }
            ]
        };

        const techDescriptions = {
            'llm': {
                description: 'Large Language Models (LLMs) like GPT-4o, Claude 3.5 Sonnet, and Gemini 2.0 represent the pinnacle of natural language AI as of December 2025. ChatGPT reached 900 million weekly active users by late 2025, with OpenAI generating $1 billion in monthly revenue. Claude 3.5 Sonnet achieves 88.7% on MMLU benchmarks and 92% on HumanEval coding tests, while being used by 90% of Fortune 100 companies. Gemini 2.0, released in December 2024, offers multimodal capabilities with native image and audio generation, operating twice as fast as Gemini 1.5 Pro. The LLM market reached $6-7 billion in 2024 and is projected to exceed $35 billion by 2030. Applications span customer service, content creation, programming assistance, research, education, and business intelligence. Challenges include computational costs, hallucination mitigation, bias reduction, and regulatory compliance.',
                references: [
                    'DemandSage. (2025). ChatGPT Users Stats - Growth & Usage Data. https://www.demandsage.com/chatgpt-statistics/',
                    'Anthropic. (2024). Introducing Claude 3.5 Sonnet. https://www.anthropic.com/news/claude-3-5-sonnet',
                    'Google DeepMind. (2024). Gemini 2.0: A new AI model for the agentic era. https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/'
                ]
            },
            'computer-vision': {
                description: 'Computer Vision has reached mature industrial adoption (TRL 9) with models like SAM (Segment Anything Model) and YOLO v10 enabling real-time object detection and segmentation with near-human accuracy. SAM, developed by Meta, can zero-shot segment any object in an image without additional training, revolutionizing image annotation and analysis. YOLO v10 achieves state-of-the-art performance with 50% less computational cost than predecessors, making it ideal for edge devices. Applications range from autonomous vehicles and medical imaging to facial recognition payment systems and automated quality control in manufacturing. The global computer vision market is expected to reach $20 billion by 2025.',
                references: [
                    'Meta AI. (2023). Segment Anything. https://ai.meta.com/research/publications/segment-anything/',
                    'Ultralytics. (2024). YOLOv10: Real-Time Object Detection. https://github.com/THU-MIG/yolov10'
                ]
            },
            'speech-recognition': {
                description: 'Speech Recognition technologies like OpenAI\'s Whisper v3 have achieved human-level parity (TRL 9), supporting multilingual transcription and translation with exceptional accuracy even in noisy environments. Whisper v3 reduces word error rates by 10-20% compared to previous versions and supports 100+ languages. Integration into consumer devices, customer service bots, and real-time translation tools is ubiquitous. Voice commerce and voice-controlled smart home adoption continue to grow, with the speech recognition market projected to surpass $30 billion by 2026.',
                references: [
                    'OpenAI. (2023). Whisper v3. https://github.com/openai/whisper',
                    'Grand View Research. (2024). Speech and Voice Recognition Market Size.'
                ]
            },
            'recommendation': {
                description: 'AI Recommendation Systems (TRL 9) are the backbone of digital platforms like Netflix, Spotify, Amazon, and TikTok, driving user engagement and revenue. Advanced algorithms now utilize graph neural networks and reinforcement learning to provide hyper-personalized content. TikTok\'s recommendation engine, utilizing real-time user interaction data, retains users for an average of 95 minutes daily. These systems are now expanding into personalized education and healthcare treatment plans.',
                references: [
                    'McKinsey. (2024). The future of personalization and how to get ready for it.',
                    'NVIDIA. (2024). Recommender Systems powered by AI.'
                ]
            },
            'machine-translation': {
                description: 'Neural Machine Translation (TRL 9) effectively eliminates language barriers for common languages, with models like Google Translate and DeepL providing context-aware, near-instant translations. Recent advances include "No Language Left Behind" (NLLB) by Meta, capable of translating 200 languages, including low-resource ones. Real-time speech-to-speech translation is becoming standard in communication apps, reshaping global business and travel.',
                references: [
                    'Meta AI. (2022). No Language Left Behind. https://ai.meta.com/research/no-language-left-behind/',
                    'DeepL. (2024). The State of Neural Machine Translation.'
                ]
            },
            'code-assistants': {
                description: 'AI code assistants like GitHub Copilot, Cursor, and Tabnine have transformed software development by providing context-aware code suggestions and automated programming assistance. GitHub Copilot surpassed 20 million all-time users by mid-2025 with over 1.3 million paid subscribers growing 30% quarter-over-quarter. The tool is now used by 90% of Fortune 100 companies. Adoption metrics show 81.4% of developers install the extension on day one, with 96% accepting suggestions immediately.',
                references: [
                    'GitHub. (2025). GitHub Copilot crosses 20M all-time users.',
                    'Stack Overflow. (2024). Developer Survey: AI Tools.'
                ]
            },
            'gen-ai-images': {
                description: 'Generative AI for images (TRL 8) has revolutionized creative industries with tools like Midjourney v6 and DALL-E 3 creating photorealistic and artistically complex images from text. Adobe Firefly and Canva have integrated these capabilities into standard design workflows. Legal and ethical frameworks regarding copyright are establishing, allowing for broader commercial use. The technology is reshaping advertising, game asset creation, and concept art.',
                references: [
                    'Midjourney. (2024). Midjourney v6 Capability Report.',
                    'Adobe. (2024). Firefly: Generative AI for Creators.'
                ]
            },
            'autonomous-l3': {
                description: 'Autonomous vehicles have made significant progress with Level 2-3 systems deployed at scale. Waymo surpassed 100 million fully autonomous miles by mid-2025. Tesla FSD users passed 1.3 billion cumulative miles. Safety data shows FSD users average 2.9 million miles between major collisions compared to the national average of 505,000 miles. However, true Level 4-5 autonomy remains elusive with technical challenges in edge cases.',
                references: [
                    'The Robot Report. (2025). Waymo reaches 100M fully autonomous miles.',
                    'Tesla. (2025). Vehicle Safety Report.'
                ]
            },
            'multimodal-ai': {
                description: 'Multimodal AI (TRL 7) models like GPT-4V and Gemini 2.0 can process and reason across text, code, audio, image, and video simultaneously. This capability allows for more natural human-AI interaction, such as analyzing medical scans with text reports or explaining complex diagrams. These models are enabling a new generation of assistants that can "see" and "hear" the world, enhancing accessibility and automation in physical environments.',
                references: [
                    'OpenAI. (2023). GPT-4V(ision) System Card.',
                    'Google. (2024). Gemini Multimodal Capabilities.'
                ]
            },
            'ai-agents': {
                description: 'AI Agents (TRL 6) represent the shift from chatbots to actionable assistants capable of executing complex workflows autonomously. Frameworks like AutoGPT and LangChain enable agents to browse the web, use software tools, and manage files to complete goals. 2025 sees the rise of "Agentic Workflows" in enterprise, automating tasks like data analysis, supply chain management, and customer support ticket resolution with minimal human oversight.',
                references: [
                    'DeepLearning.AI. (2024). AI Agents and Vector Databases.',
                    'LangChain. (2025). The State of AI Agents.'
                ]
            },
            'rag': {
                description: 'Retrieval Augmented Generation (RAG) (TRL 7) has become the standard architecture for enterprise AI, solving LLM hallucinations by grounding responses in private, verified data. Vector databases like Pinecone and Weaviate underpin these systems. RAG enables companies to securely use generic LLMs with their proprietary knowledge bases for contracts, technical documentation, and customer records.',
                references: [
                    'Pinecone. (2024). The rise of RAG in Enterprise.',
                    'NVIDIA. (2024). Retrieval Augmented Generation Explained.'
                ]
            },
            'video-generation': {
                description: 'AI video generation (TRL 6) achieved mainstream viability in 2024 with OpenAI Sora and Runway Gen-3. Sora generates videos up to 1080p, 60s long. Runway Gen-3 excels at expressive human characters. Applications include entertainment, advertising, and rapid prototyping. Limitations include occasional unrealistic physics and high computational costs.',
                references: [
                    'OpenAI. (2024). Sora Technical Report.',
                    'Runway. (2024). Gen-3 Alpha Release.'
                ]
            },
            'federated-learning': {
                description: 'Federated Learning (TRL 6) enables training models across decentralized edge devices without exchanging local data samples, preserving privacy. Google uses this for Gboard predictions. In healthcare, it allows hospitals to collaborate on diagnostic models without sharing patient identifiers, addressing HIPAA/GDPR concerns. It is key for the "Internet of Trusted Things".',
                references: [
                    'Google AI. (2023). Federated Learning at Scale.',
                    'Nature Medicine. (2024). Federated learning for medical imaging.'
                ]
            },
            'edge-ai': {
                description: 'Edge AI inference (TRL 7) allows AI execution on local devices using specialized hardware like NVIDIA Jetson and Google Coral, reducing latency and reliance on cloud connectivity. Apple\'s CoreML and TensorFlow Lite facilitate on-device processing for features like FaceID and live translation. This is crucial for privacy-preserving applications and autonomous systems operating in disconnected environments.',
                references: [
                    'NVIDIA. (2024). Jetson Orin for Edge AI.',
                    'Apple. (2024). Machine Learning on Apple Silicon.'
                ]
            },
            'ai-chips': {
                description: 'Specialized AI chips (TRL 8) like Google TPU v5, NVIDIA H100, and AWS Trainium power the AI revolution. NVIDIA dominates data center training, while companies like Cerebras push wafer-scale computing. Apple\'s Neural Engine brings teraflops of AI performance to consumer pockets, enabling the widespread deployment of local LLMs.',
                references: [
                    'Google Cloud. (2024). Cloud TPU v5e.',
                    'Cerebras. (2024). Wafer Scale Engine 3.'
                ]
            },
            'automl': {
                description: 'AutoML and Neural Architecture Search (TRL 6) automate the design of machine learning models, democratizing AI development. Platforms from Google Cloud and Azure allow non-experts to build high-quality custom models for vision and tabular data. 2025 advances focus on efficient NAS that discovers smaller, faster architectures for edge deployment.',
                references: [
                    'Google Cloud. (2024). AutoML Vision.',
                    'IEEE Spectrum. (2024). The democratization of AI via AutoML.'
                ]
            },
            'quantum-ml': {
                description: 'Quantum Machine Learning (TRL 4) explores using quantum computers to accelerate ML algorithms. While still largely experimental, hybrid quantum-classical algorithms are showing promise for specific optimization problems and kernel methods. Companies like IBM and Xanadu are providing cloud access to quantum processors for ML researchers to test small-scale quantum neural networks.',
                references: [
                    'IBM Quantum. (2025). Roadmap to Quantum Advantage.',
                    'Xanadu. (2024). PennyLane for Quantum ML.'
                ]
            },
            'neuromorphic': {
                description: 'Neuromorphic Computing (TRL 4), exemplified by Intel\'s Loihi 2, mimics the human brain\'s spiking neural networks to achieve orders of magnitude better energy efficiency than utilizing standard von Neumann architectures. These chips are particularly promising for event-based vision sensing and ultra-low-power edge robotics applications.',
                references: [
                    'Intel. (2024). Loihi 2 Neuromorphic Research Chip.',
                    'Nature Electronics. (2024). Spiking neural networks for edge efficiency.'
                ]
            },
            'ai-safety': {
                description: 'AI Safety & Alignment (TRL 5) research focuses on ensuring AI systems behave reliably and ethically. Techniques like Constitutive AI (Anthropic) and Reinforcement Learning from Human Feedback (RLHF) are standard. 2025 research targets "superalignment"—automating the safety evaluation of systems smarter than humans—and mechanistic interpretability to understand the internal logic of neural networks.',
                references: [
                    'Anthropic. (2024). Constitutional AI: Harmlessness from AI Feedback.',
                    'OpenAI. (2023). Our approach to alignment research.'
                ]
            },
            'few-shot': {
                description: 'Few-Shot and In-Context Learning (TRL 5) enables models to learn new tasks with just a few examples in the prompt, rendering model fine-tuning unnecessary for many applications. This "meta-learning" capability is a defining feature of transformer-based LLMs, drastically reducing the data requirement for customizing AI behavior.',
                references: [
                    'Brown et al. (2020). Language Models are Few-Shot Learners.',
                    'Stanford HAI. (2024). Understanding In-Context Learning.'
                ]
            },
            'causal-ai': {
                description: 'Causal AI (TRL 4) moves beyond correlation to understanding cause-and-effect relationships, addressing a major limitation of current deep learning. This field is critical for applications like medical diagnosis and economic policy planning, where understanding "what if" interventions is more important than pattern matching.',
                references: [
                    'Pearl server. (2024). Causal Inference in Statistics.',
                    'Microsoft Research. (2024). Causal AI for Decision Making.'
                ]
            },
            'explainability': {
                description: 'Explainable AI (XAI) (TRL 5) seeks to make the "black box" of deep learning transparent. Techniques like SHAP values and saliency maps help users trust model decisions in critical sectors like finance and healthcare. New approaches in 2025 allow users to converse with models to ask why a specific decision was made.',
                references: [
                    'DARPA. (2023). Explainable Artificial Intelligence (XAI).',
                    'Google PAIR. (2024). People + AI Research: Interpretability.'
                ]
            },
            'bci-ml': {
                description: 'Brain-Computer ML Interfaces (TRL 4) decode neural signals into digital commands. Neuralink\'s successful human trials in 2024 demonstrated cursor control via thought. ML algorithms are crucial for decoding the noisy, high-dimensional data from brain implants, offering new hope for restoring paralysis and communication.',
                references: [
                    'Neuralink. (2024). PRIME Study Progress.',
                    'Nature. (2024). High-performance brain-to-text communication.'
                ]
            },
            'ai-science': {
                description: 'AI for scientific discovery (TRL 6) achieved breakthrough results with AlphaFold 3 and GNoME. AlphaFold 3 predicts structures for proteins, DNA, and RNA with atomic accuracy. GNoME discovered 2.2 million new crystal structures. AI is accelerating discovery timelines by 10-100× in materials science, biology, and fusion energy.',
                references: [
                    'Google DeepMind. (2024). AlphaFold 3.',
                    'Nature. (2023). Scaling deep learning for materials discovery.'
                ]
            }
        };

        const techConnections = [
            ['llm', 'code-assistants'],
            ['llm', 'multimodal-ai'],
            ['llm', 'rag'],
            ['llm', 'ai-agents'],
            ['computer-vision', 'autonomous-l3'],
            ['computer-vision', 'gen-ai-images'],
            ['multimodal-ai', 'video-generation'],
            ['ai-chips', 'edge-ai'],
            ['ai-chips', 'llm'],
            ['automl', 'few-shot'],
            ['ai-safety', 'explainability'],
            ['ai-science', 'quantum-ml'],
            ['bci-ml', 'neuromorphic']
        ];

        // ========== GENERIC VISUALIZATION CODE - NO CHANGES NEEDED ==========

        let currentYear = 2025;
        let currentFilter = 'all';
        let selectedTech = null;

        const width = window.innerWidth;
        const height = window.innerHeight;
        const centerX = width / 2;
        const centerY = height / 2;
        const maxRadius = Math.min(width, height) * 0.4;

        const svg = d3.select('#radarSvg')
            .attr('width', width)
            .attr('height', height);

        const categoryColors = {
            research: 'var(--color-electric-blue)',
            industry: 'var(--color-gray-800)',
            emerging: 'var(--color-gray-600)',
            experimental: 'var(--color-electric-blue-dark)'
        };

        const trlColors = d3.scaleLinear()
            .domain([1, 5, 9])
            .range(['#a3a3a3', '#525252', '#4040ff']);

        let currentZoom = 1;
        const minZoom = 0.5;
        const maxZoom = 3;
        let zoomTransform = d3.zoomIdentity;

        function initVisualization() {
            setupZoom();
            setTimeout(() => {
                document.getElementById('loadingIndicator').style.display = 'none';
                renderRadar();
            }, 1500);
        }

        function setupZoom() {
            const zoom = d3.zoom()
                .scaleExtent([minZoom, maxZoom])
                .on('zoom', handleZoom);

            svg.call(zoom);

            document.getElementById('zoomIn').addEventListener('click', () => {
                svg.transition().duration(300).call(zoom.scaleBy, 1.5);
            });

            document.getElementById('zoomOut').addEventListener('click', () => {
                svg.transition().duration(300).call(zoom.scaleBy, 1 / 1.5);
            });

            document.getElementById('resetZoom').addEventListener('click', () => {
                svg.transition().duration(500).call(zoom.transform, d3.zoomIdentity);
            });
        }

        function handleZoom(event) {
            zoomTransform = event.transform;
            svg.select('.radar-content').attr('transform', zoomTransform);
        }

        function renderRadar() {
            svg.selectAll('*').remove();

            const radarContent = svg.append('g').attr('class', 'radar-content');
            const defs = svg.append('defs');

            const shadow = defs.append('filter')
                .attr('id', 'shadow')
                .attr('x', '-50%')
                .attr('y', '-50%')
                .attr('width', '200%')
                .attr('height', '200%');

            shadow.append('feDropShadow')
                .attr('dx', 2)
                .attr('dy', 2)
                .attr('stdDeviation', 3)
                .attr('flood-color', '#000')
                .attr('flood-opacity', 0.2);

            radarContent.append('circle')
                .attr('cx', centerX)
                .attr('cy', centerY)
                .attr('r', maxRadius)
                .attr('fill', '#f8fafc')
                .attr('stroke', '#e2e8f0')
                .attr('stroke-width', 2);

            for (let i = 1; i <= 9; i++) {
                const radius = (maxRadius / 9) * i;

                radarContent.append('circle')
                    .attr('cx', centerX)
                    .attr('cy', centerY)
                    .attr('r', radius)
                    .attr('fill', 'none')
                    .attr('stroke', '#cbd5e1')
                    .attr('stroke-width', 1)
                    .attr('opacity', 0.6);

                if (i % 3 === 0) {
                    radarContent.append('text')
                        .attr('x', centerX + radius + 10)
                        .attr('y', centerY + 5)
                        .attr('fill', '#1e293b')
                        .attr('font-size', '12px')
                        .attr('font-family', 'var(--font-primary)')
                        .attr('font-weight', '600')
                        .text(`TRL ${i}`);
                }
            }

            for (let i = 0; i < 12; i++) {
                const angle = (i * 30) * Math.PI / 180;
                const x2 = centerX + Math.cos(angle) * maxRadius;
                const y2 = centerY + Math.sin(angle) * maxRadius;

                radarContent.append('line')
                    .attr('x1', centerX)
                    .attr('y1', centerY)
                    .attr('x2', x2)
                    .attr('y2', y2)
                    .attr('stroke', '#e2e8f0')
                    .attr('stroke-width', 1)
                    .attr('opacity', 0.5);
            }

            const data = technologyData[currentYear] || technologyData[2025];
            const filteredData = currentFilter === 'all' ? data : data.filter(d => d.category === currentFilter);

            const techGroups = radarContent.selectAll('.tech-node')
                .data(filteredData)
                .enter()
                .append('g')
                .attr('class', 'tech-node')
                .style('cursor', 'pointer')
                .on('click', (event, d) => showTechInfo(d))
                .on('mouseover', function(event, d) {
                    d3.select(this).select('circle')
                        .transition()
                        .duration(200)
                        .attr('r', 12)
                        .attr('filter', 'url(#shadow)');
                })
                .on('mouseout', function(event, d) {
                    d3.select(this).select('circle')
                        .transition()
                        .duration(200)
                        .attr('r', 8)
                        .attr('filter', 'none');
                });

            techGroups.each(function(d) {
                const group = d3.select(this);
                const radius = (maxRadius / 9) * d.trl;
                const angleRad = (d.angle - 90) * Math.PI / 180;
                const x = centerX + Math.cos(angleRad) * radius;
                const y = centerY + Math.sin(angleRad) * radius;

                const nodeColor = getContrastColor(d.category, d.trl);
                group.append('circle')
                    .attr('cx', x)
                    .attr('cy', y)
                    .attr('r', 8)
                    .attr('fill', nodeColor.fill)
                    .attr('stroke', nodeColor.stroke)
                    .attr('stroke-width', 2);

                if (d.trl >= 6 || d.category === 'emerging') {
                    const labelRadius = radius + 25;
                    const labelX = centerX + Math.cos(angleRad) * labelRadius;
                    const labelY = centerY + Math.sin(angleRad) * labelRadius;

                    group.append('text')
                        .attr('x', labelX)
                        .attr('y', labelY)
                        .attr('text-anchor', 'middle')
                        .attr('fill', '#1e293b')
                        .attr('font-size', '10px')
                        .attr('font-family', 'var(--font-primary)')
                        .attr('font-weight', '600')
                        .text(d.name.length > 20 ? d.name.substring(0, 20) + '...' : d.name);
                }
            });

            drawConnections(filteredData);

            svg.selectAll('.tech-node')
                .style('opacity', 0)
                .transition()
                .duration(1000)
                .delay((d, i) => i * 50)
                .style('opacity', 1);
        }

        function getContrastColor(category, trl) {
            const colors = {
                research: { fill: '#4040ff', stroke: '#1e1e8f' },
                industry: { fill: '#1e293b', stroke: '#0f172a' },
                emerging: { fill: '#64748b', stroke: '#475569' },
                experimental: { fill: '#3030dd', stroke: '#1e1e8f' }
            };
            return colors[category] || colors.research;
        }

        function drawConnections(data) {
            const connectionGroup = svg.select('.radar-content').append('g').attr('class', 'connections');

            techConnections.forEach(([source, target]) => {
                const sourceNode = data.find(d => d.id === source);
                const targetNode = data.find(d => d.id === target);

                if (sourceNode && targetNode) {
                    const sourceRadius = (maxRadius / 9) * sourceNode.trl;
                    const targetRadius = (maxRadius / 9) * targetNode.trl;
                    const sourceAngle = (sourceNode.angle - 90) * Math.PI / 180;
                    const targetAngle = (targetNode.angle - 90) * Math.PI / 180;

                    const sourceX = centerX + Math.cos(sourceAngle) * sourceRadius;
                    const sourceY = centerY + Math.sin(sourceAngle) * sourceRadius;
                    const targetX = centerX + Math.cos(targetAngle) * targetRadius;
                    const targetY = centerY + Math.sin(targetAngle) * targetRadius;

                    const midX = (sourceX + targetX) / 2;
                    const midY = (sourceY + targetY) / 2;
                    const controlX = midX + (centerX - midX) * 0.3;
                    const controlY = midY + (centerY - midY) * 0.3;

                    const path = `M ${sourceX},${sourceY} Q ${controlX},${controlY} ${targetX},${targetY}`;

                    connectionGroup.append('path')
                        .attr('d', path)
                        .attr('stroke', '#3b82f6')
                        .attr('stroke-width', 1.5)
                        .attr('fill', 'none')
                        .attr('opacity', 0.6)
                        .attr('stroke-dasharray', '5,5');
                }
            });
        }

        function showTechInfo(tech) {
            selectedTech = tech;
            const infoPanel = document.getElementById('infoPanel');
            const content = document.getElementById('infoPanelContent');

            const techInfo = techDescriptions[tech.id] || {};
            const description = techInfo.description || `${tech.name} is an AI/ML technology with TRL level ${tech.trl}.`;
            const references = techInfo.references || [];

            content.innerHTML = `
                <h2 class="info-title">${tech.name}</h2>
                <div class="info-meta">
                    <span class="meta-badge meta-${tech.category}">${tech.category.toUpperCase()}</span>
                    <span class="meta-badge" style="background: ${trlColors(tech.trl)}; color: white;">TRL ${tech.trl}</span>
                    <span class="meta-badge" style="background: var(--color-gray-700); color: white;">Year: ${currentYear}</span>
                </div>
                <div class="info-description">
                    ${description}
                </div>
                <div class="progress-grid">
                    ${Object.entries(tech.progress).map(([key, value]) => `
                        <div class="progress-item">
                            <div class="progress-label">${key}</div>
                            <div class="progress-bar">
                                <div class="progress-fill" style="width: ${value}%;"></div>
                            </div>
                            <div class="progress-value">${value}%</div>
                        </div>
                    `).join('')}
                </div>
                ${references.length > 0 ? `
                    <div class="references-section">
                        <div class="references-title">Key References</div>
                        ${references.map(ref => `
                            <div class="reference-item">• ${ref}</div>
                        `).join('')}
                    </div>
                ` : ''}
            `;

            infoPanel.classList.add('active');
        }

        function closeInfoPanel() {
            document.getElementById('infoPanel').classList.remove('active');
            selectedTech = null;
        }

        function toggleTRLInfo() {
            const trlInfoPanel = document.getElementById('trlInfoPanel');
            trlInfoPanel.classList.toggle('active');
        }

        document.querySelectorAll('[data-filter]').forEach(btn => {
            btn.addEventListener('click', function() {
                document.querySelectorAll('[data-filter]').forEach(b => b.classList.remove('active'));
                this.classList.add('active');
                currentFilter = this.dataset.filter;
                renderRadar();
            });
        });

        document.querySelectorAll('[data-time]').forEach(btn => {
            btn.addEventListener('click', function() {
                document.querySelectorAll('[data-time]').forEach(b => b.classList.remove('active'));
                this.classList.add('active');
                currentYear = parseInt(this.dataset.time);
                renderRadar();
            });
        });

        window.addEventListener('resize', () => {
            location.reload();
        });

        initVisualization();
    </script>
</body>
</html>